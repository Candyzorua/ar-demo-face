<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="content-language" content="en-EN" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no" />

    <title>WebAR.rocks.face glasses VTO demo</title>

    <style type='text/css'>
      
    </style>
  </head>
  
  <body>
     <!--
      The first canvas is used by WebAR.rocks.mirror
      It is linked to a WebGL context used by the deep learning engine
      And it displays the video of the webcam.
      
      Since we need to transfer the video to a texture for face detection,
      it is not costly at all to use this texture for display.

      You can tweak the rendering of the video in WebARRocksFaceThreeHelper.js,
      by editing the fragment shader of _shps.copy
    -->
    <canvas id='WebARRocksFaceCanvas'></canvas>
    <!--
      The second canvas is used by THREE.js for 3D rendering:
    -->
    <canvas id='threeCanvas'></canvas>

    <div id='controls'>
      <div onclick = 'WebARRocksMirror.load("assets/models3D/glasses1.glb")'>Glasses 1</div>
      <div onclick = 'WebARRocksMirror.load("assets/models3D/glasses2.glb")'>Glasses 2</div>
    </div>
  </body>
</html>
